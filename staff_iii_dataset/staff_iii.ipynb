{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import wfdb\n",
    "import time\n",
    "import random\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import sys\n",
    "import pandas\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaffIIIDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, record_path, excel_path, channel, train=True, length=10000, transform=None):\n",
    "        \n",
    "        self.train = train\n",
    "        self.length = length\n",
    "        \n",
    "        with open(record_path) as fp:  \n",
    "            self.lines = fp.readlines()\n",
    "                    \n",
    "        if self.train:\n",
    "            self.lines = self.lines[:int(0.7*len(self.lines))]\n",
    "        else:\n",
    "            self.lines = self.lines[int(0.7*len(self.lines)):int(0.8*len(self.lines))]\n",
    "            \n",
    "        self.df = pandas.read_excel(excel_path)\n",
    "        self.labels = self.df[u'Unnamed: 28'][9:].as_matrix()\n",
    "        \n",
    "        # channel\n",
    "        self.channel = channel\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # extract patient_id from file_name\n",
    "        patient_id = int(self.lines[index][5:8])\n",
    "        \n",
    "        if patient_id == 28 or patient_id == 67:\n",
    "            # train\n",
    "            index = 0\n",
    "            patient_id = int(self.lines[index][5:8])\n",
    "        if  patient_id == 78 or patient_id == 103:\n",
    "            # val\n",
    "            index = 105\n",
    "            patient_id = int(self.lines[index][5:8])\n",
    "        \n",
    "        file_name = self.lines[index][:-1]\n",
    "        data, _ = wfdb.rdsamp(\"staff-iii-database-1.0.0/\" + str(file_name))\n",
    "        data = np.array(data) # (300000, 9)\n",
    "        data = data[:self.length, :]\n",
    "        \n",
    "        # extract relevant channels\n",
    "        data = data[:, self.channel]\n",
    "        \n",
    "        if self.labels[patient_id] != 'no':\n",
    "            y = 0.9\n",
    "        else:\n",
    "            y = 0.1\n",
    "        \n",
    "        return data, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        if self.train:\n",
    "            return int(0.7*519)\n",
    "        else:\n",
    "            return int(0.1*519)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arjung/opt/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:17: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_dataset = StaffIIIDataset(record_path='staff-iii-database-1.0.0/RECORDS',\n",
    "                                excel_path='staff-iii-database-1.0.0/STAFF-III-Database-Annotations.xlsx',\n",
    "                                channel=0)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=1)\n",
    "\n",
    "val_dataset = StaffIIIDataset(record_path='staff-iii-database-1.0.0/RECORDS',\n",
    "                                excel_path='staff-iii-database-1.0.0/STAFF-III-Database-Annotations.xlsx',\n",
    "                                channel=0,\n",
    "                                train=False)\n",
    "\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetQuake(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNetQuake, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=3, kernel_size=151, stride=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=3, out_channels=10, kernel_size=45, stride=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=10, out_channels=10, kernel_size=20, stride=1)\n",
    "        self.conv4 = nn.Conv1d(in_channels=10, out_channels=10, kernel_size=10, stride=1)\n",
    "        self.linear1 = nn.Linear(320, 30)\n",
    "        self.linear2 = nn.Linear(30, 10)\n",
    "        self.linear3 = nn.Linear(10, 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.bn1 = nn.BatchNorm1d(3)\n",
    "        self.bn2 = nn.BatchNorm1d(10)\n",
    "        self.bn3 = nn.BatchNorm1d(10)\n",
    "        self.bn4 = nn.BatchNorm1d(10)\n",
    "        self.mp1 = nn.MaxPool1d(6, stride=2, padding=2)\n",
    "        self.mp2 = nn.MaxPool1d(20, stride=2, padding=9)\n",
    "        self.mp3 = nn.MaxPool1d(20, stride=2, padding=9)\n",
    "        self.mp4 = nn.MaxPool1d(20, stride=2, padding=9)\n",
    "        self.drop1 = nn.Dropout(p=0.25)\n",
    "        self.drop2 = nn.Dropout(p=0.5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.bn1((self.conv1(x))))\n",
    "        x = self.mp1(x)\n",
    "        x = F.relu(self.bn2((self.conv2(x))))\n",
    "        x = self.mp2(x)\n",
    "        x = F.pad(self.conv3(x), (9, 10), \"constant\", 0)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.mp3(x)\n",
    "        x = F.pad(self.conv4(x), (4, 5), \"constant\", 0)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.mp4(x)\n",
    "        x = self.drop1(x)\n",
    "        x = torch.reshape(x, (batch_size, -1))\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, val_loader, writer, iteration):\n",
    "    \n",
    "    model.train()\n",
    "    print_every = 10\n",
    "    iteration_ = iteration\n",
    "    \n",
    "    for batch_idx, (data, y) in enumerate(train_loader):\n",
    "        \n",
    "        data = data.cuda()\n",
    "        y = y.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        y_pred = model(data)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx%print_every == 0 and batch_idx != 0:\n",
    "            \n",
    "            iteration_ += 1\n",
    "            writer.add_scalar('Loss/train', loss, iteration_)\n",
    "            \n",
    "            # validate\n",
    "            with torch.no_grad():\n",
    "\n",
    "                # test_set\n",
    "                \n",
    "                for batch_idx, (data_val, y_val) in enumerate(val_loader):\n",
    "                    a = 1\n",
    "                    break\n",
    "                \n",
    "                y_pred_val = model(data_val)\n",
    "                \n",
    "                count = 0\n",
    "                acc = 0\n",
    "                for num in y_pred_val:\n",
    "                    if int(round(num)) == int(round(y_val[count])):\n",
    "                        acc += 1\n",
    "                    count += 1\n",
    "\n",
    "                writer.add_scalar('Accuracy/val', acc, iteration_)\n",
    "\n",
    "                # train_set\n",
    "                count = 0\n",
    "                acc = 0\n",
    "                for num in y_pred:\n",
    "                    if int(round(num)) == int(round(y[count])):\n",
    "                        acc += 1\n",
    "                    count += 1\n",
    "\n",
    "                writer.add_scalar('Accuracy/train', acc, iteration_)\n",
    "    \n",
    "    return iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SummaryWriter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-beb16533dea5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/arjung2/mi_detection/runs_staff/runs_record_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannel_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SummaryWriter' is not defined"
     ]
    }
   ],
   "source": [
    "channels = {0: \"v1\", \n",
    "            1: \"v2\",\n",
    "            2: \"v3\",\n",
    "            3: \"v4\",\n",
    "            4: \"v5\",\n",
    "            5: \"v6\",\n",
    "            6: \"i\",\n",
    "            7: \"ii\",\n",
    "            8: \"iii\"}\n",
    "\n",
    "channel_1 = 0\n",
    "\n",
    "model = ConvNetQuake()\n",
    "# model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-4)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "writer = SummaryWriter('/home/jenxime/mi_detection/runs_staff/runs_record_' + str(channels[channel_1]))\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    print(\"Train Epoch: \", epoch)\n",
    "    iteration = train(model_, device, train_loader, optimizer, epoch, val_loader, writer, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('staff-iii-database-1.0.0/RECORDS') as fp:  \n",
    "    lines = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/001a\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_idx = ['data/089d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_len = []\n",
    "for index in range(len(lines)):\n",
    "    file_name = lines[index][:-1]\n",
    "    # check file_name\n",
    "    if file_name in bad_idx:\n",
    "        index = np.random.randint(0, len(lines))\n",
    "        continue\n",
    "\n",
    "    data, _ = wfdb.rdsamp(\"staff-iii-database-1.0.0/\" + str(file_name))\n",
    "    \n",
    "    j = 0\n",
    "    for i in range(0, 300000, 10000):\n",
    "        data_snippet = np.array(data[i:i+10000])\n",
    "        \n",
    "        # if not np.isnan(np.sum(data_snippet)):\n",
    "        #     j += 1\n",
    "            \n",
    "        data_snippet = torch.from_numpy(data_snippet)\n",
    "        if not torch.any(torch.isnan(data_snippet)):\n",
    "            j += 1\n",
    "    \n",
    "    # data_len.append(len(data))\n",
    "    data_len.append(10000*j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299210.01926782273"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5617.223016042727"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_len).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(data_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py27",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
